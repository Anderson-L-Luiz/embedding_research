The speaker discusses a framework for representing speech data, specifically the relationship between different levels of abstraction, such as words, utterances, and sentences, and how to efficiently extract information from this data. They consider the use of a hierarchical structure, with tags and links to represent the relationships between different levels, such as a word being part of an utterance, which is part of a sentence. They also discuss the challenge of representing non-nested relationships, such as a prosodic phrase crossing sentence boundaries. The speaker notes that the goal is to have a format that allows for efficient querying and extraction of information, such as finding all cases where a speaker's pitch was rising while another speaker was talking. They mention the use of XML and its query language, XQuery, as a potential tool for building a search interface, but note that the challenge lies in relating the feature data to the structural data.